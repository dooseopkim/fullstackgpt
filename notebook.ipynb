{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n#6.7 Recap (05:17)\\n#6.8 Stuff LCEL Chain (10:13)\\n\\n1. File들을 Load 하기.\\n - TextLoader, UnstructuredFileLoader\\n2. Split (거대한 단일 document 보다 작은 여러개를 LLM 전달할 때 검색 성능이 좋다\\n3. Ebmedding : text에 의미별로 적절한 점수를 부여해서 vector 형식으로 표현한거\\n - O\\n\\n'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xdrlib import ConversionError\n",
    "\n",
    "\"\"\"\n",
    "#6.7 Recap (05:17)\n",
    "#6.8 Stuff LCEL Chain (10:13)\n",
    "\n",
    "1. File들을 Load 하기.\n",
    " - TextLoader, UnstructuredFileLoader\n",
    "2. Split (거대한 단일 document 보다 작은 여러개를 LLM 전달할 때 검색 성능이 좋다\n",
    "3. Ebmedding : text에 의미별로 적절한 점수를 부여해서 vector 형식으로 표현한거\n",
    " - O\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-03T13:53:17.082679300Z",
     "start_time": "2025-06-03T13:53:17.050969100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # .env 파일을 환경 변수로 로드"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-03T14:15:36.037807300Z",
     "start_time": "2025-06-03T14:15:35.986406300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "# chunk_size : 얼마나 큰 덩어리로 나눌지 결정할 수 있음\n",
    "# chunk_overlap : 문장이나 문단을 분할할 때 앞 조각 일부분을 가져옴\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/Romeo and Juliet by William Shakespeare.txt\",encoding=\"utf-8\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-03T14:16:30.292800Z",
     "start_time": "2025-06-03T14:16:26.244447400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=20,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-03T14:16:32.529274700Z",
     "start_time": "2025-06-03T14:16:32.479030900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"history\": load_memory,\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(question)\n",
    "    print(result)\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-03T14:16:34.095613100Z",
     "start_time": "2025-06-03T14:16:34.065512500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Yes, Romeo did love Juliet.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Did Romeo love Juliet?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-03T14:16:37.164426600Z",
     "start_time": "2025-06-03T14:16:35.310514400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[HumanMessage(content='Did Romeo love Juliet?'),\n AIMessage(content='Yes, Romeo did love Juliet.')]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_memory({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-03T14:16:38.870512500Z",
     "start_time": "2025-06-03T14:16:38.844594700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The love between Romeo and Juliet has a tragic ending due to a series of unfortunate events, misunderstandings, and the feud between their families, the Montagues and Capulets.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Why does the love between Romeo and Juliet have a tragic ending?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-03T14:16:41.162519600Z",
     "start_time": "2025-06-03T14:16:39.685072100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[HumanMessage(content='Did Romeo love Juliet?'),\n AIMessage(content='Yes, Romeo did love Juliet.'),\n HumanMessage(content='Why does the love between Romeo and Juliet have a tragic ending?'),\n AIMessage(content='The love between Romeo and Juliet has a tragic ending due to a series of unfortunate events, misunderstandings, and the feud between their families, the Montagues and Capulets.')]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_memory({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-03T12:24:16.045306200Z",
     "start_time": "2025-06-03T12:24:16.038304800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
